{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', validation_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = mnist.train.images[2]\n",
    "plt.imshow(img.reshape((28, 28)), cmap='Greys_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# building model \n",
    "lr = 0.001\n",
    "\n",
    "x = tf.placeholder(shape=[None, 28, 28, 1], dtype=tf.float32)\n",
    "y_ = tf.placeholder(shape=[None, 28, 28, 1], dtype=tf.float32)\n",
    "\n",
    "## building encoder\n",
    "# 1st conv layer\n",
    "# 28 x 28 x16\n",
    "W_conv1 = tf.Variable(dtype=tf.float32, \n",
    "                 initial_value=tf.truncated_normal(shape=[5, 5, 1, 16], stddev=0.1))\n",
    "b_conv1 = tf.Variable(dtype=tf.float32, \n",
    "                     initial_value=tf.constant(shape=[16], value=0.1))\n",
    "conv2d_1 = tf.nn.conv2d(input=x, filter=W_conv1, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "h_conv1 = tf.nn.relu(conv2d_1 + b_conv1)\n",
    "# 14 x 14 x 16\n",
    "h_pool1 = tf.nn.max_pool(h_conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "# 2nd conv layer\n",
    "# 14 x 14 x 8\n",
    "W_conv2 = tf.Variable(dtype=tf.float32, \n",
    "                      initial_value=tf.truncated_normal(shape=[5, 5, 16, 8], stddev=0.1))\n",
    "b_conv2 = tf.Variable(dtype=tf.float32, \n",
    "                     initial_value=tf.constant(shape=[8], value=0.1))\n",
    "conv2d_2 = tf.nn.conv2d(h_pool1, W_conv2, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "h_conv2 = tf.nn.relu(conv2d_2 + b_conv2)\n",
    "# 7 x 7 x 8\n",
    "h_pool2 = tf.nn.max_pool(h_conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "# 3rd conv layer \n",
    "# 7 x 7 x8\n",
    "W_conv3 = tf.Variable(dtype=tf.float32, \n",
    "                      initial_value=tf.truncated_normal(shape=[5, 5, 8, 8], stddev=0.1))\n",
    "b_conv3 = tf.Variable(dtype=tf.float32, \n",
    "                      initial_value=tf.constant(shape=[8], value=0.1))\n",
    "conv2d_3 = tf.nn.conv2d(h_pool2, W_conv3, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "h_conv3 = tf.nn.relu(conv2d_3 + b_conv3)\n",
    "# 4 x 4 x 8\n",
    "encoded = tf.nn.max_pool(h_conv3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## buildig decoder \n",
    "# upsample 1\n",
    "# 7 x 7 x 8\n",
    "upsample1 = tf.image.resize_nearest_neighbor(encoded, (7, 7))\n",
    "\n",
    "# 1st conv layer\n",
    "# 7 x 7 x 8 \n",
    "d_W_conv1 = tf.Variable(dtype=tf.float32, \n",
    "                        initial_value=tf.truncated_normal(shape=[5, 5, 8, 8], stddev=0.1))\n",
    "d_b_conv1 = tf.Variable(dtype=tf.float32, \n",
    "                       initial_value=tf.constant(shape=[8], value=0.1))\n",
    "d_conv1 = tf.nn.conv2d(input=upsample1, filter=d_W_conv1, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "d_h_conv1 = tf.nn.relu(d_conv1 + d_b_conv1)\n",
    "\n",
    "# upsample 2\n",
    "# 14 x 14 x 8 \n",
    "upsample2 = tf.image.resize_nearest_neighbor(d_h_conv1, (14, 14))\n",
    "\n",
    "# 2nd conv layer \n",
    "# 14 x 14 x 8\n",
    "d_W_conv2 = tf.Variable(dtype=tf.float32, \n",
    "                       initial_value=tf.truncated_normal(shape=[5, 5, 8, 8], stddev=0.1))\n",
    "d_b_conv2 = tf.Variable(dtype=tf.float32, \n",
    "                       initial_value=tf.constant(shape=[8], value=0.1))\n",
    "d_conv2 = tf.nn.conv2d(input=upsample2, filter=d_W_conv2, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "d_h_conv2 = tf.nn.relu(d_conv2 + d_b_conv2)\n",
    "\n",
    "# upsample 3\n",
    "# 28 x 28 x 8\n",
    "upsample3 = tf.image.resize_nearest_neighbor(d_h_conv2, (28, 28))\n",
    "\n",
    "# 3rd conv layer\n",
    "# 28 x 28 x 16\n",
    "d_W_conv3 = tf.Variable(dtype=tf.float32, \n",
    "                       initial_value=tf.truncated_normal(shape=[5, 5, 8, 16], stddev=0.1))\n",
    "d_b_conv3 = tf.Variable(dtype=tf.float32, \n",
    "                       initial_value=tf.constant(shape=[16], value=0.1))\n",
    "d_conv3 = tf.nn.conv2d(input=upsample3, filter=d_W_conv3, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "d_h_conv3 = tf.nn.relu(d_conv3 + d_b_conv3)\n",
    "\n",
    "# 4th conv layer\n",
    "# 28 x 28 x 1\n",
    "d_W_conv4 = tf.Variable(dtype=tf.float32, \n",
    "                       initial_value=tf.truncated_normal(shape=[5, 5, 16, 1], stddev=0.1))\n",
    "d_b_conv4 = tf.Variable(dtype=tf.float32, \n",
    "                       initial_value=tf.constant(shape=[1], value=0.1))\n",
    "d_conv4 = tf.nn.conv2d(input=d_h_conv3, filter=d_W_conv4, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "logits = tf.nn.relu(d_conv4 + d_b_conv4)\n",
    "\n",
    "decoded = tf.nn.sigmoid(logits, name=\"decoded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_, logits=logits)\n",
    "cross_entropy = tf.reduce_mean(loss)\n",
    "train_step = tf.train.AdadeltaOptimizer(0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "## Training \n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(20000):\n",
    "    batch = mnist.train.next_batch(100)\n",
    "    imgs = batch[0].reshape((-1, 28, 28, 1))\n",
    "    batch_cost, _ = sess.run([cross_entropy, train_step], \n",
    "                             feed_dict={x: imgs, y_: imgs})\n",
    "\n",
    "    if i%200 == 0:\n",
    "        print(batch_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
