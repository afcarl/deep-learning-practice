{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Convolutional GANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('../MNIST_data', validation_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFfCAYAAACfj30KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhJAWoYQJIaRF/j8MrDWJxou2WgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f569c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = mnist.train.images[2]\n",
    "img = img.reshape((28, 28))\n",
    "plt.imshow(img, cmap=\"Greys_r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define handy functions \n",
    "Here, I define handy functions to be used to build the generator and the discriminator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def leaky_relu(x, alpha=0.2):\n",
    "    return tf.maximum(x * alpha, x)\n",
    "\n",
    "def conv2d(x, W_size, name, strides=[1, 1, 1, 1]):\n",
    "    \"\"\"\n",
    "    make conv layer\n",
    "    \n",
    "    :param x: input to conv layer. the size must match with W_size. \n",
    "    :param W_size: list. [filter_width, filter_height, input_channel, output_channel]\n",
    "    :param strides: list of strides of each dimension as follows. [batch, width, height, channel] \n",
    "    :return: returns conv layer with bias b added. \n",
    "    \"\"\"\n",
    "    W = tf.get_variable(shape=W_size, name=name+\"/weight\")\n",
    "    b = tf.get_variable(shape=[W_size[3]], name=name+\"/bias\")\n",
    "    conv = tf.nn.conv2d(input=x, filter=W, strides=strides, padding=\"SAME\")\n",
    "    return conv + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define inputs. \n",
    "There are two inputs needed; one is real image input for discriminator, and one is random noise input for generator. <br>\n",
    "Real image input is denoted as x, and random noise is z. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_inputs(x_size, z_size):\n",
    "    \"\"\"\n",
    "    initialize inputs x and z. \n",
    "    \n",
    "    x is for real data, and z is for random noise for generator. \n",
    "    \n",
    "    :param z_size: size of z vector\n",
    "    :return x and z \n",
    "    \"\"\"\n",
    "    x = tf.placeholder(dtype=tf.float32, shape=[None, *x_size], name=\"input_real\")\n",
    "    z = tf.placeholder(dtype=tf.float32, shape=[None, z_size], name=\"input_z\")\n",
    "    \n",
    "    return x, z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Generator \n",
    "Define a generator. <br>\n",
    "In the conv layer, I will use image resizing to avoid checker board pattern. <br>\n",
    "ref: https://distill.pub/2016/deconv-checkerboard/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(z, z_size, reuse=False, training=True):\n",
    "    \"\"\"\n",
    "    :param z: a vector with length z_size, where every elements of z is between -1 and 1\n",
    "    :param z_size: length of the z vector\n",
    "    :param reuse: boolean. whether to reuse the trained variable of weights. \n",
    "    :param training: boolean. whether it is training or not\n",
    "    :return: creates generator and return the logits and model\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(\"generator\", reuse=reuse):\n",
    "        # layer 1: fully connected layer \n",
    "        # change the length of z such that it fits to conv layer \n",
    "        W_fc1 = tf.get_variable(shape=[100, 7*7*128], name=\"fc_weight\")\n",
    "        b_fc1 = tf.get_variable(shape=[7*7*128], name=\"fc_bias\")\n",
    "        h_fc1 = tf.matmul(z, W_fc1) + b_fc1\n",
    "        # now, (7*7*128, )\n",
    "\n",
    "        # layer 2: reshape layer \n",
    "        reshape2 = tf.reshape(h_fc1, shape=[-1, 7, 7, 128])\n",
    "        # now, 7 x 7 x 128\n",
    "        batch_norm2 = tf.layers.batch_normalization(reshape2, training=training)\n",
    "        relu2 = leaky_relu(batch_norm2)\n",
    "\n",
    "        # layer 3: conv layer \n",
    "        resize3 = tf.image.resize_nearest_neighbor(images=relu2, size=(14, 14))\n",
    "        # now, 14 x 14 x 128\n",
    "        conv3 = conv2d(x=resize3, W_size=[5, 5, 128, 64], name=\"conv3\")\n",
    "        # now, 14 x 14 x 64\n",
    "        batch_norm3 = tf.layers.batch_normalization(conv3, training=training)\n",
    "        relu3 = leaky_relu(batch_norm3)\n",
    "\n",
    "        # layer 4: conv layer \n",
    "        resize4 = tf.image.resize_nearest_neighbor(images=relu3, size=(28, 28))\n",
    "        # now, 28 x 28 x 64\n",
    "        conv4 = conv2d(x=resize4, W_size=[5, 5, 64, 32], name=\"conv4\")\n",
    "        # now, 28 x 28 x 32\n",
    "        batch_norm4 = tf.layers.batch_normalization(conv4, training=training)\n",
    "        relu4 = leaky_relu(batch_norm4)\n",
    "        \n",
    "        # layer 5: output layer \n",
    "        logits = conv2d(x=relu4, W_size=[5, 5, 32, 1], name=\"output\")\n",
    "        model = tf.tanh(logits)\n",
    "        \n",
    "        return logits, model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator \n",
    "Defining discriminator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def discriminator(x, reuse=False, training=True):\n",
    "    \"\"\"\n",
    "    :param x: list [None, 28, 28, 1], where every element is between -1 and 1\n",
    "    :param reuse: boolean. whether to reuse the trained variable of weights. \n",
    "    :param training: boolean. whether it is training or not\n",
    "    :return: creates discriminator and returns logits and model \n",
    "    \"\"\"\n",
    "    with tf.variable_scope(\"discriminator\", reuse=reuse):\n",
    "        # layer 1: conv layer \n",
    "        conv1 = conv2d(x=x, W_size=[5, 5, 1, 64], strides=[1, 2, 2, 1], name=\"conv1\")\n",
    "        # now, 14 x 14 x 64\n",
    "        relu1 = leaky_relu(conv1)\n",
    "        \n",
    "        # layer 2: conv layer \n",
    "        conv2 = conv2d(x=relu1, W_size=[5, 5, 64, 128], strides=[1, 2, 2, 1], name=\"conv2\")\n",
    "        # now, 7 x 7 x 128\n",
    "        batch_norm2 = tf.layers.batch_normalization(conv2, training=training)\n",
    "        relu2 = leaky_relu(batch_norm2)\n",
    "        \n",
    "        # layer 3: reshape \n",
    "        reshape3 = tf.reshape(relu2, shape=[-1, 7*7*128])\n",
    "        \n",
    "        # layer 4: fc layer \n",
    "        W_fc4 = tf.get_variable(shape=[7*7*128, 1], name=\"fc_weight\")\n",
    "        b_fc4 = tf.get_variable(shape=[1], name=\"fc_bias\")\n",
    "        logits = tf.matmul(reshape3, W_fc4) + b_fc4\n",
    "        # now, (1, )\n",
    "        model = tf.nn.sigmoid(logits)\n",
    "        \n",
    "        return logits, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function \n",
    "Define loss function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(x, z, z_size):\n",
    "    \"\"\"\n",
    "    define the loss functions of discriminator and generator \n",
    "    \n",
    "    :param x: real image\n",
    "    :param z: random noize z \n",
    "    :param z_size: size of random noise \n",
    "    :return: d_loss, g_loss\n",
    "    \"\"\"\n",
    "    # generate fake images \n",
    "    g_logits, g_model = generator(z=z, z_size=z_size, reuse=False, training=True)\n",
    "    # using real and fake images, get outputs of discriminator  \n",
    "    d_real_logits, d_real_model = discriminator(x=x, reuse=False, training=True)\n",
    "    d_fake_logits, d_fake_model = discriminator(x=g_model, reuse=True, training=True)\n",
    "    \n",
    "    # define discriminator loss\n",
    "    d_real_loss = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_real_logits, labels=tf.ones_like(d_real_logits)))\n",
    "    d_fake_loss = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_fake_logits, labels=tf.zeros_like(d_fake_logits)))\n",
    "    d_loss = d_real_loss + d_fake_loss\n",
    "    \n",
    "    # define generator loss\n",
    "    g_loss = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_fake_logits, labels=tf.ones_like(d_fake_logits)))\n",
    "    \n",
    "    return d_loss, g_loss\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimizer(d_loss, g_loss, learning_rate, beta1):\n",
    "    # get variables to update\n",
    "    t_vars = tf.trainable_variables()\n",
    "    d_vars = [var for var in t_vars if var.name.startswith('discriminator')]\n",
    "    g_vars = [var for var in t_vars if var.name.startswith('generator')]\n",
    "    \n",
    "    # Optimize\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "        d_train_opt = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(d_loss, var_list=d_vars)\n",
    "        g_train_opt = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(g_loss, var_list=g_vars)\n",
    "\n",
    "    return d_train_opt, g_train_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build networks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# define hyperparameters\n",
    "z_size = 100\n",
    "learning_rate = 0.0002\n",
    "x_size = [28, 28, 1]\n",
    "beta1 = 0.5\n",
    "\n",
    "# initializ inputs\n",
    "x, z = initialize_inputs(x_size=x_size, z_size=z_size)\n",
    "\n",
    "# define loss function \n",
    "d_loss, g_loss = loss(x=x, z=z, z_size=z_size)\n",
    "\n",
    "# define optimizers \n",
    "d_opt, g_opt = optimizer(d_loss, g_loss, learning_rate, beta1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18433 0.140031\n",
      "2.51601 0.10062\n",
      "2.25208 0.118857\n",
      "1.44607 0.319456\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-97ae2f095ee6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m# update discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mreal_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mrand_noise\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mrand_noise\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m# update generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/leesuckgeun/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/leesuckgeun/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/leesuckgeun/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/leesuckgeun/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/leesuckgeun/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 100\n",
    "learning_rate = 0.5\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for e in range(epochs):\n",
    "        for i in range(batch_size):\n",
    "            # get imgs, reshape and rescale to pass to discriminator\n",
    "            batch = mnist.train.next_batch(batch_size)\n",
    "            real_imgs = batch[0].reshape((-1, 28, 28, 1))\n",
    "            real_imgs = real_imgs*2 - 1\n",
    "\n",
    "            # generate random vector for z \n",
    "            rand_noise = np.random.uniform(-1, 1, size=(2, z_size))\n",
    "            \n",
    "            # update discriminator \n",
    "            sess.run(d_loss, feed_dict={x:real_imgs, z:rand_noise})\n",
    "            sess.run(g_loss, feed_dict={z:rand_noise})\n",
    "            # update generator \n",
    "        # print losses \n",
    "        train_loss_d = d_loss.eval({x:real_imgs, z:rand_noise})\n",
    "        train_loss_g = g_loss.eval({z:rand_noise})\n",
    "        print(train_loss_d, train_loss_g)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# training \n",
    "batch_size = 200\n",
    "epochs = 100\n",
    "samples = []\n",
    "losses = []\n",
    "# only save generator variables\n",
    "saver = tf.train.Saver(var_list=gen_vars)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for e in range(epochs):\n",
    "        for i in range(mnist.train.num_examples//batch_size):\n",
    "            batch = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            # get imgs, reshape and rescale to pass to discriminator\n",
    "            batch_imgs = batch[0].reshape((-1, 28, 28, 1))\n",
    "            batch_imgs = batch_imgs*2 - 1\n",
    "            \n",
    "            # sample random noise for generator \n",
    "            batch_z = np.random.uniform(-1, 1, size=(batch_size, z_size))\n",
    "            \n",
    "            # run optimizers \n",
    "            sess.run(dis_opt, feed_dict={x: batch_imgs, z: batch_z})\n",
    "            sess.run(gen_opt, feed_dict={z: batch_z})\n",
    "            \n",
    "        # At the end of each epoch, get the losses and print them out\n",
    "        train_loss_d = sess.run(dis_loss, {z: batch_z, x: batch_imgs})\n",
    "        train_loss_g = gen_loss.eval({z: batch_z})\n",
    "            \n",
    "            \n",
    "        print(\"Epoch {}/{}...\".format(e+1, epochs),\n",
    "              \"Discriminator Loss: {:.4f}...\".format(train_loss_d),\n",
    "              \"Generator Loss: {:.4f}\".format(train_loss_g))\n",
    "        \n",
    "        losses.append((train_loss_d, train_loss_g))\n",
    "        \n",
    "        # sample from generator as we're training for viewing afterwards\n",
    "        sample_z = np.random.uniform(-1, 1, size=(16, z_size))\n",
    "        gen_samples = sess.run(\n",
    "                        generator_model(z, reuse=True), \n",
    "                        feed_dict={z: sample_z})\n",
    "        samples.append(gen_samples)\n",
    "        saver.save(sess, './checkpoints2/generator.ckpt')\n",
    "\n",
    "# save training generator samples\n",
    "with open('train_samples.pkl', 'wb') as f:\n",
    "    pkl.dump(samples, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
