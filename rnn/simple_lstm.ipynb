{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM with static rnn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve MNIST problem using one layer LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.contrib.rnn import BasicRNNCell, BasicLSTMCell\n",
    "from tensorflow.contrib import rnn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"../MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "n_classes = 10\n",
    "batch_size = 100\n",
    "lstm_size = 32\n",
    "num_layers = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define placeholders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# input image placeholder\n",
    "x = tf.placeholder(tf.float32, [None, 28, 28])\n",
    "# input label placeholder\n",
    "y_ = tf.placeholder(tf.float32, [None, n_classes])\n",
    "# keep prob for dropout\n",
    "keep_prob = tf.placeholder(tf.float32, shape=())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define LSTM cell "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_cell(lstm_size, keep_prob):\n",
    "    lstm = BasicLSTMCell(lstm_size)\n",
    "    # adding dropout to cell \n",
    "    lstm = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "    return lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Multi-cell lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_multi_layer_lstm(lstm_size, num_layers, batch_size, keep_prob):\n",
    "    cells = [build_cell(lstm_size, keep_prob) for _ in range(num_layers)]\n",
    "    multi_cell = tf.contrib.rnn.MultiRNNCell(cells=cells)\n",
    "    initial_state = multi_cell.zero_state(batch_size, tf.float32)\n",
    "    \n",
    "    return multi_cell, initial_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lstm, init_state = build_multi_layer_lstm(lstm_size, num_layers, batch_size, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_weights=tf.Variable(tf.random_normal([lstm_size, n_classes]))\n",
    "out_bias=tf.Variable(tf.random_normal([n_classes]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### static rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_unstack = tf.unstack(x, num=28, axis=1)\n",
    "\n",
    "outputs_static, _statifc = rnn.static_rnn(\n",
    "    cell=lstm, inputs=x_unstack, initial_state=init_state, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(outputs_static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_static = tf.matmul(outputs_static[-1], out_weights) + out_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#loss_function\n",
    "loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "        logits=y_static,labels=y_))\n",
    "#optimization\n",
    "opt=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "#model evaluation\n",
    "correct_prediction=tf.equal(tf.argmax(y_static,1),tf.argmax(y_,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training static rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#initialize variables\n",
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(1500):\n",
    "        \n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        batch_x = batch_x.reshape((-1, 28, 28))\n",
    "        sess.run(opt, feed_dict={x: batch_x, y_: batch_y, keep_prob: 0.5})\n",
    "\n",
    "        if (i+1)%50 == 0 or i==0:\n",
    "            acc = sess.run(accuracy, feed_dict={x: batch_x, y_: batch_y, keep_prob: 1})\n",
    "            los = sess.run(loss, feed_dict={x: batch_x, y_: batch_y, keep_prob: 1})\n",
    "            print(\"For iter {0}, Accuracy: {1}\".format(i+1, acc))\n",
    "            \n",
    "    #calculating test accuracy\n",
    "    test_x, test_y = mnist.test.next_batch(batch_size)\n",
    "    test_x = test_x.reshape((-1, 28, 28))\n",
    "    test_acc = sess.run(accuracy, feed_dict={x: test_x, y_: test_y, keep_prob: 1})\n",
    "    print(\"Testing Accuracy: {0:.4}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dynamic rnn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputs_dynamic, _dynamic = tf.nn.dynamic_rnn(\n",
    "    cell=lstm, inputs=x, initial_state=init_state, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_output = outputs_dynamic[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'rnn_2/transpose:0' shape=(100, 28, 32) dtype=float32>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_dynamic = tf.matmul(final_output, out_weights) + out_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add:0' shape=(100, 10) dtype=float32>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#loss_function\n",
    "loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "        logits=y_dynamic,labels=y_))\n",
    "#optimization\n",
    "opt=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "#model evaluation\n",
    "correct_prediction=tf.equal(tf.argmax(y_dynamic,1),tf.argmax(y_,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For iter 1, Accuracy: 0.1599999964237213\n",
      "For iter 50, Accuracy: 0.3499999940395355\n",
      "For iter 100, Accuracy: 0.5199999809265137\n",
      "For iter 150, Accuracy: 0.6800000071525574\n",
      "For iter 200, Accuracy: 0.699999988079071\n",
      "For iter 250, Accuracy: 0.8199999928474426\n",
      "For iter 300, Accuracy: 0.8299999833106995\n",
      "For iter 350, Accuracy: 0.8799999952316284\n",
      "For iter 400, Accuracy: 0.9200000166893005\n",
      "For iter 450, Accuracy: 0.8600000143051147\n",
      "For iter 500, Accuracy: 0.8999999761581421\n",
      "For iter 550, Accuracy: 0.8899999856948853\n",
      "For iter 600, Accuracy: 0.8799999952316284\n",
      "For iter 650, Accuracy: 0.9200000166893005\n",
      "For iter 700, Accuracy: 0.9200000166893005\n",
      "For iter 750, Accuracy: 0.9100000262260437\n",
      "For iter 800, Accuracy: 0.9300000071525574\n",
      "For iter 850, Accuracy: 0.8899999856948853\n",
      "For iter 900, Accuracy: 0.949999988079071\n",
      "For iter 950, Accuracy: 0.9599999785423279\n",
      "For iter 1000, Accuracy: 0.9300000071525574\n",
      "For iter 1050, Accuracy: 0.949999988079071\n",
      "For iter 1100, Accuracy: 0.8999999761581421\n",
      "For iter 1150, Accuracy: 0.9599999785423279\n",
      "For iter 1200, Accuracy: 0.9399999976158142\n",
      "For iter 1250, Accuracy: 0.9100000262260437\n",
      "For iter 1300, Accuracy: 0.949999988079071\n",
      "For iter 1350, Accuracy: 0.9700000286102295\n",
      "For iter 1400, Accuracy: 0.949999988079071\n",
      "For iter 1450, Accuracy: 0.9300000071525574\n",
      "For iter 1500, Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "#initialize variables\n",
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(1500):\n",
    "        \n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        batch_x = batch_x.reshape((batch_size, -1, 28))\n",
    "        sess.run(opt, feed_dict={x: batch_x, y_: batch_y, keep_prob: 0.5})\n",
    "\n",
    "        if (i+1)%50 == 0 or i==0:\n",
    "            acc = sess.run(accuracy, feed_dict={x: batch_x, y_: batch_y, keep_prob: 1})\n",
    "            los = sess.run(loss, feed_dict={x: batch_x, y_: batch_y, keep_prob: 1})\n",
    "            print(\"For iter {0}, Accuracy: {1}\".format(i+1, acc))\n",
    "            \n",
    "    #calculating test accuracy\n",
    "    test_x, test_y = mnist.test.next_batch(batch_size)\n",
    "    test_x = test_x.reshape((-1, 28, 28))\n",
    "    test_acc = sess.run(accuracy, feed_dict={x: test_x, y_: test_y, keep_prob: 1})\n",
    "    print(\"Testing Accuracy: {0:.4}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_fw, init_state_fw = build_multi_layer_lstm(lstm_size, num_layers, batch_size, keep_prob)\n",
    "lstm_bw, init_state_bw = build_multi_layer_lstm(lstm_size, num_layers, batch_size, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_weights=tf.Variable(tf.random_normal([lstm_size, n_classes]))\n",
    "out_bias=tf.Variable(tf.random_normal([n_classes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs_dynamic, _dynamic = tf.nn.bidirectional_dynamic_rnn(\n",
    "    cell_fw=lstm_fw, cell_bw=lstm_bw, inputs=x, \n",
    "    initial_state_fw=init_state_fw, initial_state_bw=init_state_bw, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'bidirectional_rnn_1/fw/fw/transpose:0' shape=(100, 28, 32) dtype=float32>,\n",
       " <tf.Tensor 'ReverseV2_1:0' shape=(100, 28, 32) dtype=float32>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO \n",
    "# decide what to do with outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
